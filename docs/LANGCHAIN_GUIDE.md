# ğŸ”— LangChain Integration Guide

> **AgentHQì—ì„œ LangChainì„ í™œìš©í•˜ëŠ” ì™„ì „ ê°€ì´ë“œ**

---

## ëª©ì°¨
1. [ì™œ LangChainì¸ê°€?](#ì™œ-langchainì¸ê°€)
2. [í•µì‹¬ ê°œë…](#í•µì‹¬-ê°œë…)
3. [Agent ì•„í‚¤í…ì²˜](#agent-ì•„í‚¤í…ì²˜)
4. [êµ¬í˜„ íŒ¨í„´](#êµ¬í˜„-íŒ¨í„´)
5. [Best Practices](#best-practices)

---

## ì™œ LangChainì¸ê°€?

### ë¬¸ì œì  (Before LangChain)
```python
# ì§ì ‘ OpenAI SDK ì‚¬ìš© - ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": prompt},
    ]
)
result = response.choices[0].message.content

# ë¬¸ì œì :
# - Tool í†µí•© ì–´ë ¤ì›€
# - Memory ê´€ë¦¬ ë³µì¡
# - ì—ëŸ¬ ì²˜ë¦¬ ë°˜ë³µ
# - ì¬ì‚¬ìš©ì„± ë‚®ìŒ
# - ëª¨ë‹ˆí„°ë§ ë¶€ì¡±
```

### í•´ê²°ì±… (After LangChain)
```python
# LangChainìœ¼ë¡œ êµ¬ì¡°í™” - í™•ì¥ ê°€ëŠ¥, ìœ ì§€ë³´ìˆ˜ ì‰¬ì›€
from langchain_openai import ChatOpenAI
from langchain.agents import create_openai_functions_agent, AgentExecutor
from langchain.memory import ConversationBufferMemory

# LLM ì´ˆê¸°í™”
llm = ChatOpenAI(model="gpt-4", callbacks=[langfuse_handler])

# Tools ì •ì˜
tools = [web_search_tool, google_docs_tool]

# Agent ìƒì„±
agent = create_openai_functions_agent(llm, tools, prompt)
executor = AgentExecutor(agent=agent, tools=tools, memory=memory)

# ì‹¤í–‰
result = await executor.ainvoke({"input": prompt})

# ì¥ì :
# âœ… Tool í†µí•© ê°„í¸
# âœ… Memory ìë™ ê´€ë¦¬
# âœ… ì—ëŸ¬ ì²˜ë¦¬ ë‚´ì¥
# âœ… ì¬ì‚¬ìš© ê°€ëŠ¥
# âœ… ëª¨ë‹ˆí„°ë§ í†µí•© (LangFuse)
```

---

## í•µì‹¬ ê°œë…

### 1. Chains
> **ìˆœì°¨ì ì¸ LLM í˜¸ì¶œ íŒŒì´í”„ë¼ì¸**

```python
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate

# Simple Chain
prompt = PromptTemplate.from_template("Translate {text} to {language}")
chain = LLMChain(llm=llm, prompt=prompt)

result = chain.run(text="Hello", language="Korean")
# Output: "ì•ˆë…•í•˜ì„¸ìš”"
```

### 2. Agents
> **ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ììœ¨ì ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” ì‹œìŠ¤í…œ**

```python
from langchain.agents import create_openai_functions_agent

# Agent = LLM + Tools + Prompt + Memory
agent = create_openai_functions_agent(
    llm=llm,
    tools=[search_tool, calculator_tool],
    prompt=agent_prompt,
)

executor = AgentExecutor(agent=agent, tools=tools, memory=memory)
```

**Agent ì‘ë™ ë°©ì‹**:
```
1. User Input â†’ Agent
2. Agent â†’ LLM: "ì–´ë–¤ toolì„ ì‚¬ìš©í• ì§€ ê²°ì •"
3. LLM â†’ Agent: "web_search ì‚¬ìš©"
4. Agent â†’ Tool: web_search("query")
5. Tool â†’ Agent: search results
6. Agent â†’ LLM: "ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ë‹µë³€ ìƒì„±"
7. LLM â†’ Agent: Final answer
8. Agent â†’ User: ë‹µë³€ ë°˜í™˜
```

### 3. Tools
> **Agentê°€ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ ë‹¨ìœ„**

```python
from langchain.tools import Tool

def search_web(query: str) -> str:
    """ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    # ì‹¤ì œ ê²€ìƒ‰ ë¡œì§
    return "ê²€ìƒ‰ ê²°ê³¼..."

# Tool ì •ì˜
search_tool = Tool(
    name="web_search",
    func=search_web,
    description="ì›¹ì—ì„œ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì…ë ¥: ê²€ìƒ‰ì–´(str)",
)
```

### 4. Memory
> **ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ ìœ ì§€**

```python
from langchain.memory import ConversationBufferMemory

# ëŒ€í™” íˆìŠ¤í† ë¦¬ ì €ì¥
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
)

# Agentì— ì—°ê²°
executor = AgentExecutor(agent=agent, tools=tools, memory=memory)

# ì²« ë²ˆì§¸ ëŒ€í™”
await executor.ainvoke({"input": "ë‚´ ì´ë¦„ì€ Johnì´ì•¼"})

# ë‘ ë²ˆì§¸ ëŒ€í™” - ì´ì „ ëŒ€í™” ê¸°ì–µ
result = await executor.ainvoke({"input": "ë‚´ ì´ë¦„ì´ ë­ì˜€ì§€?"})
# Output: "ë‹¹ì‹ ì˜ ì´ë¦„ì€ Johnì…ë‹ˆë‹¤."
```

---

## Agent ì•„í‚¤í…ì²˜

### AgentHQ Agent ê³„ì¸µ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          BaseAgent (ì¶”ìƒ í´ë˜ìŠ¤)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ LLM Provider ì¶”ìƒí™”                    â”‚
â”‚ â€¢ Memory ê´€ë¦¬                            â”‚
â”‚ â€¢ LangFuse í†µí•©                          â”‚
â”‚ â€¢ Error Handling                         â”‚
â”‚ â€¢ Retry Logic                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼       â–¼       â–¼       â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Research  â”‚ â”‚Docsâ”‚ â”‚Sheetsâ”‚ â”‚ Slides  â”‚
â”‚  Agent    â”‚ â”‚Agntâ”‚ â”‚Agent â”‚ â”‚ Agent   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ê° Agent:
  - íŠ¹í™”ëœ Tools
  - íŠ¹í™”ëœ Prompts
  - íŠ¹í™”ëœ Workflows
```

### BaseAgent êµ¬ì¡°

```python
class BaseAgent(ABC):
    """ëª¨ë“  Agentì˜ ê¸°ë°˜ í´ë˜ìŠ¤"""

    def __init__(self, user_id, session_id, llm_provider, ...):
        self.llm = self._create_llm(...)          # LLM ì´ˆê¸°í™”
        self.memory = ConversationBufferMemory()   # Memory ì´ˆê¸°í™”
        self.langfuse_handler = get_handler(...)   # ëª¨ë‹ˆí„°ë§
        self.tools = []                            # Tools (í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ ì •ì˜)
        self.agent_executor = None                 # Executor

    @abstractmethod
    def _create_tools(self) -> List[Tool]:
        """í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        pass

    @abstractmethod
    def _create_prompt(self) -> ChatPromptTemplate:
        """í•˜ìœ„ í´ë˜ìŠ¤ì—ì„œ êµ¬í˜„"""
        pass

    async def run(self, prompt: str) -> dict:
        """Agent ì‹¤í–‰"""
        result = await self.agent_executor.ainvoke(...)
        return result
```

---

## êµ¬í˜„ íŒ¨í„´

### Pattern 1: Research Agent

```python
class ResearchAgent(BaseAgent):
    """ì›¹ ë¦¬ì„œì¹˜ ì „ë¬¸ Agent"""

    def _create_tools(self) -> List[Tool]:
        return [
            Tool(
                name="web_search",
                func=DuckDuckGoSearchRun().run,
                description="ì›¹ ê²€ìƒ‰ ë„êµ¬. ìµœì‹  ì •ë³´ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©.",
            ),
            Tool(
                name="scrape_website",
                func=self._scrape_website,
                description="ì›¹í˜ì´ì§€ ë‚´ìš©ì„ ì¶”ì¶œ. URLì„ ì…ë ¥ë°›ìŒ.",
            ),
        ]

    def _create_prompt(self) -> ChatPromptTemplate:
        return ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬ì„œì²˜ì…ë‹ˆë‹¤.

ì±…ì„:
1. ì›¹ì—ì„œ ì •í™•í•˜ê³  ìµœì‹  ì •ë³´ ê²€ìƒ‰
2. ì—¬ëŸ¬ ì†ŒìŠ¤ì˜ ì •ë³´ë¥¼ ë¶„ì„ ë° ì¢…í•©
3. ëª¨ë“  ì£¼ì¥ì— ëŒ€í•œ ì¶œì²˜ ì œê³µ

ì¶œë ¥ í˜•ì‹:
- í•µì‹¬ ë°œê²¬ì‚¬í•­ (ë¶ˆë › í¬ì¸íŠ¸)
- ìƒì„¸ ë¶„ì„
- ì¶œì²˜ ì¸ìš© (ë²ˆí˜¸ ë§¤ê¸´ ëª©ë¡ + URL)
            """),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
```

### Pattern 2: Google Docs Agent

```python
class DocsAgent(BaseAgent):
    """Google Docs ìƒì„± ì „ë¬¸ Agent"""

    def _create_tools(self) -> List[Tool]:
        return [
            Tool(
                name="create_document",
                func=self._create_document,
                description="ìƒˆ Google Docs ìƒì„±. ì œëª©ê³¼ ë‚´ìš©ì„ ì…ë ¥ë°›ìŒ.",
            ),
            Tool(
                name="add_heading",
                func=self._add_heading,
                description="ë¬¸ì„œì— ì œëª© ì¶”ê°€. ë ˆë²¨(1-3)ê³¼ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ìŒ.",
            ),
            Tool(
                name="add_paragraph",
                func=self._add_paragraph,
                description="ë¬¸ì„œì— ë‹¨ë½ ì¶”ê°€. í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ìŒ.",
            ),
            Tool(
                name="add_table",
                func=self._add_table,
                description="ë¬¸ì„œì— í‘œ ì¶”ê°€. í–‰/ì—´ ë°ì´í„°ë¥¼ ì…ë ¥ë°›ìŒ.",
            ),
        ]

    def _create_prompt(self) -> ChatPromptTemplate:
        return ChatPromptTemplate.from_messages([
            ("system", """ë‹¹ì‹ ì€ ì „ë¬¸ ë¬¸ì„œ ì‘ì„± Agentì…ë‹ˆë‹¤.

ì‘ì—… ìˆœì„œ:
1. create_documentë¡œ ìƒˆ ë¬¸ì„œ ìƒì„±
2. add_headingìœ¼ë¡œ ì œëª© êµ¬ì¡° ìƒì„±
3. add_paragraphë¡œ ë‚´ìš© ì‘ì„±
4. add_tableë¡œ í‘œ ì¶”ê°€ (í•„ìš”ì‹œ)

ìŠ¤íƒ€ì¼ ê°€ì´ë“œ:
- ì œëª©: Heading 1-3 ì‚¬ìš©
- ë³¸ë¬¸: ëª…í™•í•˜ê³  ê°„ê²°í•˜ê²Œ
- í‘œ: ë°ì´í„° ì‹œê°í™”ì— í™œìš©
            """),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
```

### Pattern 3: Multi-Agent Collaboration

```python
async def create_research_report(topic: str, user_id: str):
    """ì—¬ëŸ¬ Agentë¥¼ í˜‘ì—…ì‹œì¼œ ë¦¬í¬íŠ¸ ìƒì„±"""

    # 1. Research Agent: ì •ë³´ ìˆ˜ì§‘
    research_agent = ResearchAgent(user_id=user_id)
    research_result = await research_agent.run(
        prompt=f"{topic}ì— ëŒ€í•œ ìµœì‹  ì •ë³´ ì¡°ì‚¬"
    )

    # 2. Docs Agent: ë¬¸ì„œ ì‘ì„±
    docs_agent = DocsAgent(user_id=user_id)
    doc_result = await docs_agent.run(
        prompt=f"ë‹¤ìŒ ë¦¬ì„œì¹˜ ê²°ê³¼ë¡œ ë³´ê³ ì„œ ì‘ì„±: {research_result['output']}",
        context={"research_data": research_result},
    )

    # 3. Sheets Agent: ë°ì´í„° ì‹œê°í™” (Optional)
    if has_numeric_data(research_result):
        sheets_agent = SheetsAgent(user_id=user_id)
        await sheets_agent.run(
            prompt="ë¦¬ì„œì¹˜ ë°ì´í„°ë¥¼ ì°¨íŠ¸ë¡œ ì‹œê°í™”",
            context={"data": extract_data(research_result)},
        )

    return {
        "document_url": doc_result.get("document_url"),
        "research_sources": research_result.get("sources"),
    }
```

---

## Best Practices

### 1. Prompt Engineering

**âŒ ë‚˜ìœ ì˜ˆ**:
```python
prompt = "ë¦¬ì„œì¹˜í•´ì¤˜"
```

**âœ… ì¢‹ì€ ì˜ˆ**:
```python
prompt = """ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬ì„œì²˜ì…ë‹ˆë‹¤.

ì‘ì—…: {task_description}

ìš”êµ¬ì‚¬í•­:
- ìµœì†Œ 3ê°œ ì´ìƒì˜ ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì¶œì²˜ ì‚¬ìš©
- 2024ë…„ ì´í›„ ì •ë³´ ìš°ì„ 
- ê° ì£¼ì¥ì— ëŒ€í•œ ì¶œì²˜ ëª…ì‹œ

ì¶œë ¥ í˜•ì‹:
1. ìš”ì•½ (3-5 ë¬¸ì¥)
2. í•µì‹¬ ë°œê²¬ì‚¬í•­ (ë¶ˆë › í¬ì¸íŠ¸)
3. ìƒì„¸ ë¶„ì„
4. ì¶œì²˜ ëª©ë¡

ì œì•½ì‚¬í•­:
- ì˜ê²¬ê³¼ ì‚¬ì‹¤ ëª…í™•íˆ êµ¬ë¶„
- ì •ë³´ ë¶€ì¡± ì‹œ ëª…ì‹œì  ì–¸ê¸‰
"""
```

### 2. Tool Design

**ì›ì¹™**:
- **ë‹¨ì¼ ì±…ì„**: ê° Toolì€ í•˜ë‚˜ì˜ ëª…í™•í•œ ê¸°ëŠ¥
- **ëª…í™•í•œ ì„¤ëª…**: Tool descriptionì€ êµ¬ì²´ì ìœ¼ë¡œ
- **íƒ€ì… íŒíŒ…**: ì…ì¶œë ¥ íƒ€ì… ëª…ì‹œ
- **ì—ëŸ¬ ì²˜ë¦¬**: ì˜ˆì™¸ ìƒí™© ì²˜ë¦¬

**ì˜ˆì‹œ**:
```python
from typing import Optional

def search_web(
    query: str,
    max_results: int = 5,
    language: str = "en",
) -> Optional[str]:
    """
    ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        query: ê²€ìƒ‰ì–´
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 5)
        language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: "en")

    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´ (JSON í˜•ì‹) ë˜ëŠ” None

    Raises:
        ValueError: queryê°€ ë¹„ì–´ìˆì„ ë•Œ
        APIError: ê²€ìƒ‰ API ì˜¤ë¥˜ ì‹œ
    """
    if not query:
        raise ValueError("ê²€ìƒ‰ì–´ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    try:
        results = search_api.search(query, max_results, language)
        return json.dumps(results, ensure_ascii=False)
    except Exception as e:
        logger.error(f"Search failed: {e}")
        return None
```

### 3. Memory Management

**ì „ëµ**:
- **ConversationBufferMemory**: ì§§ì€ ëŒ€í™” (<10í„´)
- **ConversationSummaryMemory**: ê¸´ ëŒ€í™” (ìš”ì•½ ì‚¬ìš©)
- **VectorStoreMemory**: ê´€ë ¨ ëŒ€í™” ê²€ìƒ‰ (ì‹œë§¨í‹± ì„œì¹˜)

```python
# ì§§ì€ ëŒ€í™”
from langchain.memory import ConversationBufferMemory

memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True,
    max_token_limit=2000,  # í† í° ì œí•œ
)

# ê¸´ ëŒ€í™” (ìš”ì•½)
from langchain.memory import ConversationSummaryMemory

memory = ConversationSummaryMemory(
    llm=llm,
    memory_key="chat_history",
    return_messages=True,
)

# ì‹œë§¨í‹± ê²€ìƒ‰
from langchain.memory import VectorStoreRetrieverMemory
from langchain.vectorstores import PGVector

vectorstore = PGVector(...)
retriever = vectorstore.as_retriever(search_kwargs={"k": 5})

memory = VectorStoreRetrieverMemory(
    retriever=retriever,
    memory_key="chat_history",
)
```

### 4. Error Handling

```python
from tenacity import retry, stop_after_attempt, wait_exponential

class RobustAgent(BaseAgent):
    """ì—ëŸ¬ì— ê°•í•œ Agent"""

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=4, max=10),
    )
    async def run(self, prompt: str) -> dict:
        """Retry logicì´ ì ìš©ëœ ì‹¤í–‰"""
        try:
            result = await self.agent_executor.ainvoke(
                {"input": prompt},
                config={
                    "callbacks": [self.langfuse_handler],
                    "max_execution_time": 300,  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                },
            )

            return {
                "output": result.get("output"),
                "success": True,
            }

        except TimeoutError as e:
            logger.error(f"Agent timeout: {e}")
            return {
                "output": None,
                "error": "ì‘ì—… ì‹œê°„ ì´ˆê³¼",
                "success": False,
            }

        except Exception as e:
            logger.error(f"Agent error: {e}", exc_info=True)
            return {
                "output": None,
                "error": str(e),
                "success": False,
            }

        finally:
            # LangFuseì— ë¡œê·¸ ì „ì†¡
            self.langfuse_handler.flush()
```

### 5. Performance Optimization

```python
# Streaming ì‘ë‹µ (ì‚¬ìš©ì ê²½í—˜ ê°œì„ )
async def run_with_streaming(self, prompt: str):
    """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ ì‹¤í–‰"""
    async for chunk in self.agent_executor.astream(
        {"input": prompt},
        config={"callbacks": [self.langfuse_handler]},
    ):
        if "output" in chunk:
            yield chunk["output"]

# ë³‘ë ¬ Tool ì‹¤í–‰
from langchain.agents import ParallelToolsAgent

agent = ParallelToolsAgent(
    llm=llm,
    tools=tools,
    max_parallel_tools=3,  # ìµœëŒ€ 3ê°œ ë³‘ë ¬ ì‹¤í–‰
)

# Caching (ë°˜ë³µ í˜¸ì¶œ ìµœì í™”)
from langchain.cache import RedisCache
import langchain

langchain.llm_cache = RedisCache(redis_url="redis://localhost:6379")
```

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangChain Docs](https://python.langchain.com/)
- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)
- [LangChain Tools](https://python.langchain.com/docs/modules/agents/tools/)
- [LangChain Memory](https://python.langchain.com/docs/modules/memory/)

### ì˜ˆì œ ì½”ë“œ
- [LangChain Examples](https://github.com/langchain-ai/langchain/tree/master/docs/docs/modules/agents)
- [Agent Templates](https://github.com/langchain-ai/langchain/tree/master/templates)

### ì»¤ë®¤ë‹ˆí‹°
- [LangChain Discord](https://discord.gg/langchain)
- [LangChain Twitter](https://twitter.com/LangChainAI)

---

**Last Updated**: 2024-10-29
**Version**: 1.0
