# ğŸ“Š LangFuse Setup & Integration Guide

> **AgentHQ LLM Observability & Monitoring ì™„ì „ ê°€ì´ë“œ**

---

## ëª©ì°¨
1. [LangFuseë€?](#langfuseë€)
2. [ì„¤ì¹˜ ë° ì„¤ì •](#ì„¤ì¹˜-ë°-ì„¤ì •)
3. [í†µí•© ë°©ë²•](#í†µí•©-ë°©ë²•)
4. [ëŒ€ì‹œë³´ë“œ í™œìš©](#ëŒ€ì‹œë³´ë“œ-í™œìš©)
5. [ê³ ê¸‰ ê¸°ëŠ¥](#ê³ ê¸‰-ê¸°ëŠ¥)

---

## LangFuseë€?

### LangFuse = LLM Observability Platform

**í•µì‹¬ ê¸°ëŠ¥**:
- ğŸ” **Tracing**: ëª¨ë“  LLM í˜¸ì¶œ ì¶”ì 
- ğŸ’° **Cost Tracking**: ë¹„ìš© ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
- ğŸ“Š **Analytics**: ì„±ëŠ¥ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸
- ğŸ“ **Prompt Management**: í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬
- ğŸ§ª **A/B Testing**: í”„ë¡¬í”„íŠ¸ ì‹¤í—˜ ë° ë¹„êµ
- ğŸ”” **Alerting**: ì´ìƒ ìƒí™© ì•Œë¦¼

### ì™œ LangFuseê°€ í•„ìš”í•œê°€?

**Without LangFuse**:
```
âŒ LLM í˜¸ì¶œ ë¹„ìš© ëª¨ë¦„ â†’ ì˜ˆì‚° ì´ˆê³¼ ìœ„í—˜
âŒ ì„±ëŠ¥ ë³‘ëª© ì°¾ê¸° ì–´ë ¤ì›€ â†’ ìµœì í™” ë¶ˆê°€
âŒ ì—ëŸ¬ ì›ì¸ íŒŒì•… ì–´ë ¤ì›€ â†’ ë””ë²„ê¹… ì‹œê°„ ì¦ê°€
âŒ í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ í‰ê°€ ë¶ˆê°€ â†’ ê°œì„  ì†ë„ ì €í•˜
```

**With LangFuse**:
```
âœ… ë¹„ìš© ì‹¤ì‹œê°„ ì¶”ì  â†’ ì˜ˆì‚° ê´€ë¦¬ ê°€ëŠ¥
âœ… ë³‘ëª© êµ¬ê°„ ì‹œê°í™” â†’ íƒ€ê²Ÿ ìµœì í™”
âœ… ì—ëŸ¬ íŠ¸ë ˆì´ìŠ¤ ì œê³µ â†’ ë¹ ë¥¸ ë””ë²„ê¹…
âœ… í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ë¹„êµ â†’ ë°ì´í„° ê¸°ë°˜ ê°œì„ 
```

---

## ì„¤ì¹˜ ë° ì„¤ì •

### Option 1: Cloud (ê¶Œì¥ - ë¹ ë¥¸ ì‹œì‘)

#### 1. íšŒì›ê°€ì…

```bash
# 1. https://cloud.langfuse.com ì ‘ì†
# 2. Sign up with GitHub/Google
# 3. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±: "AgentHQ"
```

#### 2. API Keys íšë“

```bash
# Settings > API Keys > Create New Key

# 3ê°€ì§€ í‚¤ ë³µì‚¬:
# - Public Key:  pk-lf-...
# - Secret Key:  sk-lf-...
# - Host URL:    https://cloud.langfuse.com
```

#### 3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# backend/.env
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxx
LANGFUSE_HOST=https://cloud.langfuse.com
```

#### 4. Python íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
cd backend
pip install langfuse==2.6.0 langfuse-langchain==2.6.0
```

---

### Option 2: Self-Hosted (ì—”í„°í”„ë¼ì´ì¦ˆ)

#### 1. Docker Composeë¡œ ë°°í¬

```yaml
# docker-compose.langfuse.yml
version: '3.8'

services:
  langfuse-server:
    image: langfuse/langfuse:latest
    container_name: langfuse-server
    ports:
      - "3000:3000"
    environment:
      # Database
      DATABASE_URL: postgresql://postgres:postgres@langfuse-db:5432/langfuse

      # Auth
      NEXTAUTH_SECRET: your-super-secret-key-change-me
      NEXTAUTH_URL: http://localhost:3000

      # Optional: Email (SMTP)
      # EMAIL_FROM: noreply@yourdomain.com
      # SMTP_HOST: smtp.gmail.com
      # SMTP_PORT: 587
      # SMTP_USER: your-email@gmail.com
      # SMTP_PASSWORD: your-app-password

    depends_on:
      - langfuse-db
    restart: unless-stopped

  langfuse-db:
    image: postgres:15-alpine
    container_name: langfuse-db
    environment:
      POSTGRES_DB: langfuse
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    volumes:
      - langfuse-db-data:/var/lib/postgresql/data
    restart: unless-stopped

volumes:
  langfuse-db-data:
```

#### 2. ì‹¤í–‰

```bash
# ì‹¤í–‰
docker-compose -f docker-compose.langfuse.yml up -d

# ë¡œê·¸ í™•ì¸
docker-compose -f docker-compose.langfuse.yml logs -f

# ì ‘ì†
# http://localhost:3000
```

#### 3. ì´ˆê¸° ì„¤ì •

```bash
# 1. http://localhost:3000 ì ‘ì†
# 2. ê³„ì • ìƒì„±
# 3. í”„ë¡œì íŠ¸ ìƒì„±
# 4. API Keys ìƒì„±

# .env ì„¤ì •
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=http://localhost:3000
```

---

## í†µí•© ë°©ë²•

### 1. ê¸°ë³¸ í†µí•© (LangChain)

```python
# backend/app/core/langfuse.py

from langfuse import Langfuse
from langfuse.callback import CallbackHandler
import os

# LangFuse Client ì´ˆê¸°í™”
langfuse_client = Langfuse(
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    host=os.getenv("LANGFUSE_HOST"),
)


def get_langfuse_handler(
    user_id: str | None = None,
    session_id: str | None = None,
    metadata: dict | None = None,
) -> CallbackHandler:
    """LangFuse Callback Handler ìƒì„±"""
    return CallbackHandler(
        public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
        secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
        host=os.getenv("LANGFUSE_HOST"),
        user_id=user_id,
        session_id=session_id,
        metadata=metadata or {},
    )
```

### 2. Agent í†µí•©

```python
# backend/app/agents/base.py

from app.core.langfuse import get_langfuse_handler

class BaseAgent:
    def __init__(self, user_id: str, session_id: str = None):
        self.user_id = user_id
        self.session_id = session_id or f"session_{user_id}"

        # LangFuse Handler
        self.langfuse_handler = get_langfuse_handler(
            user_id=self.user_id,
            session_id=self.session_id,
            metadata={
                "agent_type": self.__class__.__name__,
                "version": "1.0",
            },
        )

        # LLMì— Handler ì—°ê²°
        self.llm = ChatOpenAI(
            model="gpt-4",
            callbacks=[self.langfuse_handler],
        )

    async def run(self, prompt: str):
        """Agent ì‹¤í–‰ - ìë™ìœ¼ë¡œ LangFuseì— ë¡œê¹…"""
        result = await self.agent_executor.ainvoke(
            {"input": prompt},
            config={
                "callbacks": [self.langfuse_handler],
            },
        )
        return result
```

### 3. Custom Trace ì¶”ê°€

```python
from langfuse.decorators import observe, langfuse_context

@observe()  # ìë™ Trace
async def process_document(doc_id: str, user_id: str):
    """ë¬¸ì„œ ì²˜ë¦¬ - LangFuseê°€ ìë™ ì¶”ì """

    # Span ì¶”ê°€ (ì„¸ë¶€ ë‹¨ê³„ ì¶”ì )
    langfuse_context.update_current_trace(
        user_id=user_id,
        metadata={"doc_id": doc_id},
    )

    # 1. ë¬¸ì„œ ë¡œë“œ
    with langfuse_context.observe(name="load_document") as span:
        doc = load_document(doc_id)
        span.update(output={"doc_size": len(doc)})

    # 2. Agent ì‹¤í–‰
    agent = ResearchAgent(user_id=user_id)
    result = await agent.run(f"Summarize: {doc}")

    # 3. ê²°ê³¼ ì €ì¥
    with langfuse_context.observe(name="save_result"):
        save_result(result)

    return result
```

### 4. Score & Feedback ì¶”ê°€

```python
from langfuse import Langfuse

langfuse = Langfuse()

# User Feedback ê¸°ë¡
def record_user_feedback(trace_id: str, rating: int, comment: str = ""):
    """ì‚¬ìš©ì í”¼ë“œë°± ê¸°ë¡"""
    langfuse.score(
        trace_id=trace_id,
        name="user_rating",
        value=rating,  # 1-5
        comment=comment,
    )

# Quality Score ê¸°ë¡
def record_quality_score(trace_id: str, quality: float):
    """í’ˆì§ˆ ì ìˆ˜ ê¸°ë¡ (ìë™ í‰ê°€)"""
    langfuse.score(
        trace_id=trace_id,
        name="quality_score",
        value=quality,  # 0-1
    )

# ì‚¬ìš© ì˜ˆì‹œ
@observe()
async def generate_report(prompt: str, user_id: str):
    result = await agent.run(prompt)

    # ìë™ í’ˆì§ˆ í‰ê°€
    quality = evaluate_quality(result)
    record_quality_score(
        trace_id=langfuse_context.get_current_trace_id(),
        quality=quality,
    )

    return result
```

---

## ëŒ€ì‹œë³´ë“œ í™œìš©

### 1. Traces (í˜¸ì¶œ ì¶”ì )

**ê¸°ëŠ¥**:
- ëª¨ë“  LLM í˜¸ì¶œ ë‚´ì—­ í™•ì¸
- ì…ë ¥/ì¶œë ¥ ê²€í† 
- ì‹¤í–‰ ì‹œê°„ ë¶„ì„
- ì—ëŸ¬ ì¶”ì 

**í™œìš© ë°©ë²•**:
```
1. Traces íƒ­ ì ‘ì†
2. í•„í„°ë§:
   - User ID
   - Session ID
   - Date Range
   - Status (success/error)
3. ìƒì„¸ ë³´ê¸°:
   - Input Prompt
   - Output
   - Token Usage
   - Latency
   - Error Message (ìˆì„ ê²½ìš°)
```

### 2. Sessions (ì„¸ì…˜ ì¶”ì )

**ê¸°ëŠ¥**:
- ì‚¬ìš©ìë³„ ëŒ€í™” íë¦„ í™•ì¸
- Multi-turn ëŒ€í™” ë¶„ì„
- ì„¸ì…˜ ì„±ëŠ¥ í‰ê°€

**í™œìš© ë°©ë²•**:
```
1. Sessions íƒ­ ì ‘ì†
2. íŠ¹ì • ì„¸ì…˜ ì„ íƒ
3. ëŒ€í™” íë¦„ í™•ì¸:
   - ê° í„´ì˜ Input/Output
   - ëˆ„ì  ë¹„ìš©
   - í‰ê·  ì‘ë‹µ ì‹œê°„
```

### 3. Metrics (ì„±ëŠ¥ ì§€í‘œ)

**ì£¼ìš” ì§€í‘œ**:
```yaml
ë¹„ìš©:
  - Total Cost: ì´ ë¹„ìš©
  - Cost per User: ì‚¬ìš©ìë‹¹ ë¹„ìš©
  - Cost per Session: ì„¸ì…˜ë‹¹ ë¹„ìš©

ì„±ëŠ¥:
  - Avg Latency: í‰ê·  ì‘ë‹µ ì‹œê°„
  - P95 Latency: 95% ë°±ë¶„ìœ„ìˆ˜
  - Error Rate: ì—ëŸ¬ ë°œìƒë¥ 

ì‚¬ìš©ëŸ‰:
  - Total Tokens: ì´ í† í° ìˆ˜
  - Tokens per Request: ìš”ì²­ë‹¹ í† í°
  - Requests per Minute: ë¶„ë‹¹ ìš”ì²­ ìˆ˜
```

**í™œìš©**:
```
1. Metrics íƒ­ ì ‘ì†
2. ê¸°ê°„ ì„ íƒ (Last 7 days, Last 30 days, Custom)
3. ê·¸ë˜í”„ ë¶„ì„:
   - Cost Trend: ë¹„ìš© ì¶”ì´
   - Latency Distribution: ì‘ë‹µ ì‹œê°„ ë¶„í¬
   - Token Usage: í† í° ì‚¬ìš© íŒ¨í„´
4. ì´ìƒ íƒì§€:
   - ë¹„ìš© ê¸‰ì¦ ì‹œì  í™•ì¸
   - ì„±ëŠ¥ ì €í•˜ êµ¬ê°„ íŒŒì•…
```

### 4. Prompts (í”„ë¡¬í”„íŠ¸ ê´€ë¦¬)

**ê¸°ëŠ¥**:
- í”„ë¡¬í”„íŠ¸ ë²„ì „ ê´€ë¦¬
- A/B í…ŒìŠ¤íŠ¸
- ì„±ëŠ¥ ë¹„êµ

**í™œìš© ë°©ë²•**:
```python
# 1. í”„ë¡¬í”„íŠ¸ ë“±ë¡
from langfuse import Langfuse

langfuse = Langfuse()

langfuse.create_prompt(
    name="research_agent_v1",
    prompt="You are a research agent...",
    config={"model": "gpt-4", "temperature": 0.7},
)

# 2. í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
prompt = langfuse.get_prompt("research_agent_v1")

# 3. LLM í˜¸ì¶œ
result = llm.invoke(prompt.prompt)

# 4. ëŒ€ì‹œë³´ë“œì—ì„œ ì„±ëŠ¥ ë¹„êµ
# - v1 vs v2 ë¹„êµ
# - í‰ê·  í’ˆì§ˆ ì ìˆ˜
# - ë¹„ìš© ì°¨ì´
```

### 5. Users & Analytics

**ì‚¬ìš©ì ë¶„ì„**:
```
1. Users íƒ­ ì ‘ì†
2. ì‚¬ìš©ìë³„ í†µê³„:
   - ì´ ìš”ì²­ ìˆ˜
   - ì´ ë¹„ìš©
   - í‰ê·  ë§Œì¡±ë„
   - ì£¼ìš” ì‚¬ìš© ê¸°ëŠ¥
3. ì½”í˜¸íŠ¸ ë¶„ì„:
   - ì‹ ê·œ vs ê¸°ì¡´ ì‚¬ìš©ì
   - ì‚¬ìš© íŒ¨í„´ ì°¨ì´
```

---

## ê³ ê¸‰ ê¸°ëŠ¥

### 1. Custom Metadata

```python
@observe()
async def complex_workflow(user_id: str, task_type: str):
    # Traceì— Custom Metadata ì¶”ê°€
    langfuse_context.update_current_trace(
        user_id=user_id,
        metadata={
            "task_type": task_type,
            "environment": "production",
            "version": "1.2.0",
            "feature_flags": {
                "new_ui": True,
                "beta_feature": False,
            },
        },
        tags=["production", "high-priority"],
    )

    # ì‘ì—… ìˆ˜í–‰
    result = await perform_task(task_type)

    # ê²°ê³¼ ë©”íƒ€ë°ì´í„°
    langfuse_context.update_current_observation(
        output={
            "result": result,
            "metrics": {
                "processing_time": 1.23,
                "items_processed": 42,
            },
        },
    )

    return result
```

### 2. Error Tracking & Alerting

```python
from langfuse import Langfuse

langfuse = Langfuse()

@observe()
async def resilient_agent_run(prompt: str, user_id: str):
    try:
        result = await agent.run(prompt)
        return result

    except Exception as e:
        # ì—ëŸ¬ ì •ë³´ ìƒì„¸ ê¸°ë¡
        langfuse_context.update_current_trace(
            status_message=str(e),
            level="ERROR",
            metadata={
                "error_type": type(e).__name__,
                "error_details": str(e),
                "user_id": user_id,
                "prompt": prompt,
            },
        )

        # ëŒ€ì‹œë³´ë“œì—ì„œ Alert ì„¤ì •:
        # 1. Alerts íƒ­
        # 2. Create Alert Rule
        # 3. Condition: error_rate > 5% in 5 minutes
        # 4. Notification: Email/Slack

        raise
```

### 3. A/B Testing

```python
import random
from langfuse import Langfuse

langfuse = Langfuse()

@observe()
async def ab_test_prompts(user_input: str, user_id: str):
    """ë‘ ê°œì˜ í”„ë¡¬í”„íŠ¸ ë²„ì „ A/B í…ŒìŠ¤íŠ¸"""

    # 50/50 ëœë¤ ë°°ì •
    variant = "A" if random.random() < 0.5 else "B"

    # Variant Metadata ê¸°ë¡
    langfuse_context.update_current_trace(
        metadata={
            "ab_test": True,
            "variant": variant,
        },
    )

    # í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
    if variant == "A":
        prompt = langfuse.get_prompt("research_agent_v1")
    else:
        prompt = langfuse.get_prompt("research_agent_v2")

    # LLM í˜¸ì¶œ
    result = await llm.invoke(prompt.prompt.format(input=user_input))

    # ê²°ê³¼ ê¸°ë¡
    langfuse_context.update_current_observation(
        output=result,
    )

    return result

# ëŒ€ì‹œë³´ë“œì—ì„œ ë¶„ì„:
# 1. Traces í•„í„°: metadata.variant = "A" or "B"
# 2. Score ë¹„êµ: í‰ê·  user_rating
# 3. í†µê³„ì  ìœ ì˜ì„± ê²€ì •
# 4. ìŠ¹ì ê²°ì • ë° ë°°í¬
```

### 4. Cost Optimization

```python
from langfuse import Langfuse

langfuse = Langfuse()

@observe()
async def cost_aware_agent(prompt: str, budget: float):
    """ë¹„ìš© ì œì•½ ì¡°ê±´ í•˜ì—ì„œ Agent ì‹¤í–‰"""

    # í˜„ì¬ ì„¸ì…˜ ë¹„ìš© í™•ì¸
    session_id = langfuse_context.get_current_trace_id()
    session_cost = get_session_cost(session_id)

    if session_cost >= budget:
        raise ValueError(f"Budget exceeded: {session_cost} >= {budget}")

    # ì €ë¹„ìš© ëª¨ë¸ ì„ íƒ
    if budget - session_cost < 0.10:  # $0.10 ë¯¸ë§Œ ë‚¨ìŒ
        model = "gpt-3.5-turbo"  # ì €ë ´í•œ ëª¨ë¸
    else:
        model = "gpt-4-turbo"  # ê³ ê¸‰ ëª¨ë¸

    langfuse_context.update_current_trace(
        metadata={
            "budget": budget,
            "session_cost": session_cost,
            "model_selected": model,
        },
    )

    # LLM í˜¸ì¶œ
    llm = ChatOpenAI(model=model)
    result = await llm.ainvoke(prompt)

    return result


def get_session_cost(session_id: str) -> float:
    """LangFuse APIë¡œ ì„¸ì…˜ ë¹„ìš© ì¡°íšŒ"""
    # LangFuse Dashboardì—ì„œ Session Cost API ì‚¬ìš©
    # ë˜ëŠ” Tracesë¥¼ ì§‘ê³„í•˜ì—¬ ê³„ì‚°
    pass
```

---

## Best Practices

### 1. êµ¬ì¡°í™”ëœ Metadata

```python
# âŒ Bad
langfuse_context.update_current_trace(
    metadata={"info": "some data"},
)

# âœ… Good
langfuse_context.update_current_trace(
    metadata={
        "user": {
            "id": user_id,
            "tier": "premium",
            "country": "KR",
        },
        "task": {
            "type": "research",
            "priority": "high",
            "estimated_tokens": 1000,
        },
        "context": {
            "session_length": 5,
            "previous_tasks": ["task1", "task2"],
        },
    },
)
```

### 2. Meaningful Trace Names

```python
# âŒ Bad
@observe(name="function1")
async def func():
    pass

# âœ… Good
@observe(name="research_agent:web_search")
async def research_web_search():
    pass

@observe(name="docs_agent:create_document")
async def create_google_doc():
    pass
```

### 3. Score Every Trace

```python
@observe()
async def generate_with_quality_check(prompt: str):
    result = await agent.run(prompt)

    # ìë™ í’ˆì§ˆ í‰ê°€
    quality_score = evaluate_output_quality(result)

    langfuse.score(
        trace_id=langfuse_context.get_current_trace_id(),
        name="output_quality",
        value=quality_score,
        comment=f"Automated quality check",
    )

    return result
```

### 4. Regular Dashboard Review

```
ì¼ì¼:
  - Error Rate í™•ì¸
  - ë¹„ìš© ì¶”ì´ ëª¨ë‹ˆí„°ë§

ì£¼ê°„:
  - ì„±ëŠ¥ íŠ¸ë Œë“œ ë¶„ì„
  - í”„ë¡¬í”„íŠ¸ A/B í…ŒìŠ¤íŠ¸ ê²°ê³¼ í™•ì¸
  - ì‚¬ìš©ì í”¼ë“œë°± ë¦¬ë·°

ì›”ê°„:
  - ë¹„ìš© ìµœì í™” ê¸°íšŒ íƒìƒ‰
  - ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ ê²€í† 
  - ì•„í‚¤í…ì²˜ ê°œì„  ê³„íš
```

---

## ì°¸ê³  ìë£Œ

### ê³µì‹ ë¬¸ì„œ
- [LangFuse Docs](https://langfuse.com/docs)
- [Python SDK](https://langfuse.com/docs/sdk/python)
- [LangChain Integration](https://langfuse.com/docs/integrations/langchain)

### ì˜ˆì œ
- [LangFuse Examples](https://github.com/langfuse/langfuse-docs/tree/main/cookbook)

### ì»¤ë®¤ë‹ˆí‹°
- [Discord](https://discord.gg/langfuse)
- [GitHub Discussions](https://github.com/langfuse/langfuse/discussions)

---

**Last Updated**: 2024-10-29
**Version**: 1.0
