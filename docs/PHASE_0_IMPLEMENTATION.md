# ğŸš€ Phase 0: Foundation Enhancement - ì‹¤í–‰ ê°€ì´ë“œ

> **ëª©í‘œ**: LangChain/LangFuse í†µí•©ìœ¼ë¡œ ì„¸ê³„ ìµœê³  ìˆ˜ì¤€ ê¸°ë°˜ êµ¬ì¶•
> **ê¸°ê°„**: 2ì£¼ (Week 1-2)
> **ìš°ì„ ìˆœìœ„**: P0 (CRITICAL)

---

## ğŸ“‹ ëª©ì°¨
1. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
2. [Week 1: LangChain & LangFuse í†µí•©](#week-1-langchain--langfuse-í†µí•©)
3. [Week 2: Prompt Management & Testing](#week-2-prompt-management--testing)
4. [ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸](#ê²€ì¦-ì²´í¬ë¦¬ìŠ¤íŠ¸)

---

## í™˜ê²½ ì„¤ì •

### 1. ì˜ì¡´ì„± ì—…ë°ì´íŠ¸

```bash
cd backend

# requirements.txtì— ì¶”ê°€
cat >> requirements.txt << 'EOF'

# LangChain Core
langchain==0.1.0
langchain-core==0.1.0
langchain-community==0.0.10

# LangChain Providers
langchain-openai==0.0.2
langchain-anthropic==0.1.0

# LangFuse
langfuse==2.6.0
langfuse-langchain==2.6.0

# Additional Tools
duckduckgo-search==4.1.0
EOF

# ì„¤ì¹˜
pip install -r requirements.txt
```

### 2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .envì— ì¶”ê°€
cat >> .env << 'EOF'

# LangChain
LANGCHAIN_TRACING_V2=true
LANGCHAIN_PROJECT=agenthq

# LangFuse
LANGFUSE_PUBLIC_KEY=pk-lf-...
LANGFUSE_SECRET_KEY=sk-lf-...
LANGFUSE_HOST=https://cloud.langfuse.com  # or self-hosted URL

# LLM Providers
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
EOF
```

### 3. LangFuse ì„¤ì •

#### Option A: Cloud (ê¶Œì¥ - ë¹ ë¥¸ ì‹œì‘)
```bash
# 1. https://cloud.langfuse.com íšŒì›ê°€ì…
# 2. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±: "AgentHQ"
# 3. Settings > API Keysì—ì„œ í‚¤ ë³µì‚¬
# 4. .envì— ì¶”ê°€
```

#### Option B: Self-Hosted (ì—”í„°í”„ë¼ì´ì¦ˆ)
```bash
# docker-compose.ymlì— ì¶”ê°€
cat >> docker-compose.yml << 'EOF'
  langfuse-server:
    image: langfuse/langfuse:latest
    ports:
      - "3000:3000"
    environment:
      - DATABASE_URL=postgresql://postgres:postgres@postgres:5432/langfuse
      - NEXTAUTH_SECRET=your-secret-here
      - NEXTAUTH_URL=http://localhost:3000
    depends_on:
      - postgres
EOF

docker-compose up -d langfuse-server
```

---

## Week 1: LangChain & LangFuse í†µí•©

### Day 1-2: BaseAgent êµ¬ì¡° êµ¬ì¶•

#### 1. Agent ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±

```bash
mkdir -p backend/app/agents/tools
touch backend/app/agents/__init__.py
touch backend/app/agents/base.py
touch backend/app/agents/research_agent.py
touch backend/app/agents/docs_agent.py
touch backend/app/agents/sheets_agent.py
touch backend/app/agents/slides_agent.py
touch backend/app/agents/memory_manager.py
touch backend/app/agents/tools/__init__.py
touch backend/app/agents/tools/web_search.py
touch backend/app/agents/tools/google_apis.py
```

#### 2. LangFuse Client ì´ˆê¸°í™”

```bash
# backend/app/core/langfuse.py ìƒì„±
cat > backend/app/core/langfuse.py << 'EOF'
"""LangFuse integration for LLM observability."""

import os
from functools import wraps
from typing import Any, Callable

from langfuse import Langfuse
from langfuse.callback import CallbackHandler

# Initialize LangFuse client
langfuse_client = Langfuse(
    public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
    secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
    host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
)


def get_langfuse_handler(
    user_id: str | None = None,
    session_id: str | None = None,
    metadata: dict[str, Any] | None = None,
) -> CallbackHandler:
    """
    Create LangFuse callback handler for tracing.

    Args:
        user_id: User identifier
        session_id: Session identifier
        metadata: Additional metadata

    Returns:
        CallbackHandler instance
    """
    return CallbackHandler(
        public_key=os.getenv("LANGFUSE_PUBLIC_KEY"),
        secret_key=os.getenv("LANGFUSE_SECRET_KEY"),
        host=os.getenv("LANGFUSE_HOST", "https://cloud.langfuse.com"),
        user_id=user_id,
        session_id=session_id,
        metadata=metadata,
    )


def trace_llm(
    name: str | None = None,
    metadata: dict[str, Any] | None = None,
):
    """
    Decorator for tracing LLM calls with LangFuse.

    Usage:
        @trace_llm(name="research_agent", metadata={"version": "1.0"})
        def my_agent_function():
            pass
    """
    def decorator(func: Callable) -> Callable:
        @wraps(func)
        async def async_wrapper(*args, **kwargs):
            trace_name = name or func.__name__
            trace = langfuse_client.trace(
                name=trace_name,
                metadata=metadata,
            )

            try:
                result = await func(*args, **kwargs, trace_id=trace.id)
                trace.update(output=result)
                return result
            except Exception as e:
                trace.update(
                    output=None,
                    status_message=str(e),
                    level="ERROR",
                )
                raise

        @wraps(func)
        def sync_wrapper(*args, **kwargs):
            trace_name = name or func.__name__
            trace = langfuse_client.trace(
                name=trace_name,
                metadata=metadata,
            )

            try:
                result = func(*args, **kwargs, trace_id=trace.id)
                trace.update(output=result)
                return result
            except Exception as e:
                trace.update(
                    output=None,
                    status_message=str(e),
                    level="ERROR",
                )
                raise

        # Detect if function is async
        import asyncio
        if asyncio.iscoroutinefunction(func):
            return async_wrapper
        else:
            return sync_wrapper

    return decorator


__all__ = [
    "langfuse_client",
    "get_langfuse_handler",
    "trace_llm",
]
EOF
```

#### 3. BaseAgent ì¶”ìƒ í´ë˜ìŠ¤ êµ¬í˜„

```bash
# backend/app/agents/base.py ìƒì„±
cat > backend/app/agents/base.py << 'EOF'
"""Base agent class with LangChain and LangFuse integration."""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Optional

from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

from app.core.config import settings
from app.core.langfuse import get_langfuse_handler, trace_llm


class BaseAgent(ABC):
    """
    Base class for all agents with LangChain and LangFuse integration.

    Features:
        - LLM provider abstraction (OpenAI, Anthropic)
        - LangFuse tracing and monitoring
        - Memory management
        - Tool integration
        - Error handling and retry logic
    """

    def __init__(
        self,
        user_id: str,
        session_id: Optional[str] = None,
        llm_provider: str = "openai",
        model: str = "gpt-4-turbo-preview",
        temperature: float = 0.7,
        max_tokens: int = 4000,
        memory: Optional[ConversationBufferMemory] = None,
    ):
        """
        Initialize base agent.

        Args:
            user_id: User identifier for tracking
            session_id: Session identifier for grouping
            llm_provider: "openai" or "anthropic"
            model: Model name
            temperature: LLM temperature (0-1)
            max_tokens: Max output tokens
            memory: Optional memory instance
        """
        self.user_id = user_id
        self.session_id = session_id or f"session_{user_id}"

        # Initialize LLM
        self.llm = self._create_llm(llm_provider, model, temperature, max_tokens)

        # Initialize memory
        self.memory = memory or ConversationBufferMemory(
            memory_key="chat_history",
            return_messages=True,
        )

        # LangFuse callback handler
        self.langfuse_handler = get_langfuse_handler(
            user_id=self.user_id,
            session_id=self.session_id,
            metadata=self._get_metadata(),
        )

        # Tools will be set by subclasses
        self.tools: List[Any] = []

        # Agent executor (initialized in subclasses)
        self.agent_executor: Optional[AgentExecutor] = None

    def _create_llm(
        self,
        provider: str,
        model: str,
        temperature: float,
        max_tokens: int,
    ):
        """Create LLM instance based on provider."""
        if provider == "openai":
            return ChatOpenAI(
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                callbacks=[self.langfuse_handler] if hasattr(self, 'langfuse_handler') else None,
            )
        elif provider == "anthropic":
            return ChatAnthropic(
                model=model,
                temperature=temperature,
                max_tokens=max_tokens,
                callbacks=[self.langfuse_handler] if hasattr(self, 'langfuse_handler') else None,
            )
        else:
            raise ValueError(f"Unsupported LLM provider: {provider}")

    @abstractmethod
    def _get_metadata(self) -> Dict[str, Any]:
        """Get agent metadata for LangFuse tracking."""
        pass

    @abstractmethod
    def _create_tools(self) -> List[Any]:
        """Create agent-specific tools."""
        pass

    @abstractmethod
    def _create_prompt(self) -> ChatPromptTemplate:
        """Create agent-specific prompt template."""
        pass

    def initialize_agent(self):
        """Initialize agent with tools and prompt."""
        # Create tools
        self.tools = self._create_tools()

        # Create prompt
        prompt = self._create_prompt()

        # Create agent
        agent = create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt,
        )

        # Create agent executor
        self.agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            memory=self.memory,
            verbose=settings.DEBUG,
            max_iterations=10,
            max_execution_time=300,  # 5 minutes
            callbacks=[self.langfuse_handler],
        )

    @trace_llm(name="agent_run")
    async def run(
        self,
        prompt: str,
        context: Optional[Dict[str, Any]] = None,
        trace_id: Optional[str] = None,
    ) -> Dict[str, Any]:
        """
        Run agent with prompt.

        Args:
            prompt: User prompt
            context: Additional context
            trace_id: LangFuse trace ID (injected by decorator)

        Returns:
            Agent output dictionary
        """
        if not self.agent_executor:
            self.initialize_agent()

        try:
            # Prepare input
            agent_input = {
                "input": prompt,
                **(context or {}),
            }

            # Run agent
            result = await self.agent_executor.ainvoke(
                agent_input,
                config={
                    "callbacks": [self.langfuse_handler],
                    "metadata": {
                        "trace_id": trace_id,
                        "user_id": self.user_id,
                        "session_id": self.session_id,
                    },
                },
            )

            return {
                "output": result.get("output"),
                "intermediate_steps": result.get("intermediate_steps", []),
                "success": True,
            }

        except Exception as e:
            # Log error to LangFuse
            self.langfuse_handler.flush()

            return {
                "output": None,
                "error": str(e),
                "success": False,
            }

    def clear_memory(self):
        """Clear conversation memory."""
        self.memory.clear()


__all__ = ["BaseAgent"]
EOF
```

### Day 3-4: Research Agent êµ¬í˜„

```bash
# backend/app/agents/research_agent.py ìƒì„±
cat > backend/app/agents/research_agent.py << 'EOF'
"""Research Agent for web search and analysis."""

from typing import Any, Dict, List

from langchain.tools import Tool
from langchain_community.tools import DuckDuckGoSearchRun
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from app.agents.base import BaseAgent


class ResearchAgent(BaseAgent):
    """
    Agent for web research and information gathering.

    Features:
        - Web search (DuckDuckGo)
        - Content extraction
        - Source citation
        - Information synthesis
    """

    def _get_metadata(self) -> Dict[str, Any]:
        """Get agent metadata."""
        return {
            "agent_type": "research",
            "version": "1.0",
            "capabilities": ["web_search", "citation", "synthesis"],
        }

    def _create_tools(self) -> List[Tool]:
        """Create research tools."""
        # DuckDuckGo search tool
        search = DuckDuckGoSearchRun()

        tools = [
            Tool(
                name="web_search",
                func=search.run,
                description=(
                    "Useful for searching the web for current information. "
                    "Input should be a search query string. "
                    "Returns search results with titles and snippets."
                ),
            ),
        ]

        return tools

    def _create_prompt(self) -> ChatPromptTemplate:
        """Create research agent prompt."""
        system_message = """You are a professional research agent.

Your responsibilities:
1. Search the web for accurate, up-to-date information
2. Analyze and synthesize information from multiple sources
3. Provide citations for all claims
4. Present information in a clear, structured format

Guidelines:
- Always cite your sources with URLs
- Prioritize recent and authoritative sources
- Cross-reference information when possible
- Clearly distinguish facts from opinions
- Be transparent about information gaps

Output format:
- Key findings (bullet points)
- Detailed analysis
- Source citations (numbered list with URLs)
"""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])

        return prompt


__all__ = ["ResearchAgent"]
EOF
```

### Day 5: ì²« í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

```bash
# backend/tests/test_agents.py ìƒì„±
mkdir -p backend/tests
cat > backend/tests/test_research_agent.py << 'EOF'
"""Tests for Research Agent."""

import pytest
from app.agents.research_agent import ResearchAgent


@pytest.mark.asyncio
async def test_research_agent_creation():
    """Test research agent initialization."""
    agent = ResearchAgent(
        user_id="test_user",
        session_id="test_session",
    )

    assert agent.user_id == "test_user"
    assert agent.session_id == "test_session"
    assert agent.llm is not None


@pytest.mark.asyncio
async def test_research_agent_run():
    """Test research agent execution."""
    agent = ResearchAgent(
        user_id="test_user",
        session_id="test_session",
    )

    result = await agent.run(
        prompt="What are the latest trends in AI in 2024?",
    )

    assert result["success"] is True
    assert result["output"] is not None
    assert len(result["output"]) > 0


@pytest.mark.asyncio
async def test_research_agent_with_context():
    """Test research agent with additional context."""
    agent = ResearchAgent(
        user_id="test_user",
        session_id="test_session",
    )

    result = await agent.run(
        prompt="Summarize key points about LangChain",
        context={
            "focus_areas": ["architecture", "use_cases"],
        },
    )

    assert result["success"] is True
    assert "LangChain" in result["output"]


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
EOF

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
cd backend
pytest tests/test_research_agent.py -v
```

### Day 6-7: ë‚˜ë¨¸ì§€ Agent Stub ìƒì„±

```bash
# Google Docs Agent stub
cat > backend/app/agents/docs_agent.py << 'EOF'
"""Google Docs Agent for document generation."""

from typing import Any, Dict, List

from langchain.tools import Tool
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder

from app.agents.base import BaseAgent


class DocsAgent(BaseAgent):
    """
    Agent for Google Docs generation.

    TODO: Implement in Phase 1
    """

    def _get_metadata(self) -> Dict[str, Any]:
        return {
            "agent_type": "docs",
            "version": "0.1",
            "status": "stub",
        }

    def _create_tools(self) -> List[Tool]:
        # TODO: Implement Google Docs API tools
        return []

    def _create_prompt(self) -> ChatPromptTemplate:
        prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a document generation agent. (TODO: Implement)"),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad"),
        ])
        return prompt


__all__ = ["DocsAgent"]
EOF

# ê°™ì€ ë°©ì‹ìœ¼ë¡œ sheets_agent.py, slides_agent.py ìƒì„±
# (êµ¬ì¡°ëŠ” ë™ì¼, êµ¬í˜„ì€ Phase 1ì—ì„œ ì™„ì„±)
```

---

## Week 2: Prompt Management & Testing

### Day 8-9: Prompt Management System

```bash
# backend/app/prompts/ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p backend/app/prompts/templates
touch backend/app/prompts/__init__.py

# Prompt Registry êµ¬í˜„
cat > backend/app/prompts/registry.py << 'EOF'
"""Prompt Registry for version management."""

import json
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from pydantic import BaseModel


class PromptVersion(BaseModel):
    """Prompt version model."""
    version: str
    template: str
    variables: List[str]
    metadata: Dict[str, Any]
    created_at: datetime
    performance_score: Optional[float] = None


class PromptRegistry:
    """
    Registry for managing prompt templates and versions.

    Features:
        - Version management
        - A/B testing support
        - Performance tracking (via LangFuse)
        - Rollback capability
    """

    def __init__(self, storage_path: str = "prompts/templates"):
        self.storage_path = Path(storage_path)
        self.storage_path.mkdir(parents=True, exist_ok=True)
        self._cache: Dict[str, List[PromptVersion]] = {}

    def register(
        self,
        name: str,
        template: str,
        variables: List[str],
        metadata: Optional[Dict[str, Any]] = None,
        version: Optional[str] = None,
    ) -> PromptVersion:
        """Register new prompt or version."""
        # Auto-generate version if not provided
        if version is None:
            existing = self.list_versions(name)
            version = f"v{len(existing) + 1}"

        prompt_version = PromptVersion(
            version=version,
            template=template,
            variables=variables,
            metadata=metadata or {},
            created_at=datetime.now(),
        )

        # Save to file
        self._save_version(name, prompt_version)

        # Update cache
        if name not in self._cache:
            self._cache[name] = []
        self._cache[name].append(prompt_version)

        return prompt_version

    def get(
        self,
        name: str,
        version: Optional[str] = None,
    ) -> Optional[PromptVersion]:
        """Get prompt by name and version."""
        versions = self.list_versions(name)

        if not versions:
            return None

        if version is None:
            # Return latest version
            return versions[-1]

        # Find specific version
        for v in versions:
            if v.version == version:
                return v

        return None

    def list_versions(self, name: str) -> List[PromptVersion]:
        """List all versions of a prompt."""
        if name in self._cache:
            return self._cache[name]

        # Load from file
        file_path = self.storage_path / f"{name}.json"
        if not file_path.exists():
            return []

        with open(file_path, "r") as f:
            data = json.load(f)

        versions = [PromptVersion(**v) for v in data]
        self._cache[name] = versions

        return versions

    def _save_version(self, name: str, version: PromptVersion):
        """Save prompt version to file."""
        versions = self.list_versions(name)
        versions.append(version)

        file_path = self.storage_path / f"{name}.json"
        with open(file_path, "w") as f:
            json.dump(
                [v.dict() for v in versions],
                f,
                indent=2,
                default=str,
            )


# Global registry instance
prompt_registry = PromptRegistry()


__all__ = ["PromptRegistry", "PromptVersion", "prompt_registry"]
EOF

# Research Agent í”„ë¡¬í”„íŠ¸ ë“±ë¡
cat > backend/app/prompts/templates/research.py << 'EOF'
"""Research agent prompt templates."""

from app.prompts.registry import prompt_registry

# Register default research prompt
prompt_registry.register(
    name="research_agent",
    template="""You are a professional research agent.

Your responsibilities:
1. Search the web for accurate, up-to-date information
2. Analyze and synthesize information from multiple sources
3. Provide citations for all claims
4. Present information in a clear, structured format

Topic: {topic}
Focus areas: {focus_areas}

Guidelines:
- Always cite your sources with URLs
- Prioritize recent and authoritative sources
- Cross-reference information when possible
- Clearly distinguish facts from opinions

Output format:
- Key findings (bullet points)
- Detailed analysis
- Source citations
""",
    variables=["topic", "focus_areas"],
    metadata={
        "agent": "research",
        "purpose": "web_research",
        "language": "en",
    },
    version="v1",
)
EOF
```

### Day 10-12: Comprehensive Testing

```bash
# pytest.ini ì„¤ì •
cat > backend/pytest.ini << 'EOF'
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    -v
    --cov=app
    --cov-report=html
    --cov-report=term-missing
    --cov-fail-under=80
asyncio_mode = auto
EOF

# í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„±
cat > backend/tests/test_integration.py << 'EOF'
"""Integration tests for agent system."""

import pytest
from app.agents.research_agent import ResearchAgent
from app.prompts.registry import prompt_registry


@pytest.mark.asyncio
async def test_research_agent_with_prompt_registry():
    """Test research agent with prompt from registry."""
    # Get prompt from registry
    prompt_version = prompt_registry.get("research_agent", version="v1")
    assert prompt_version is not None

    # Create agent
    agent = ResearchAgent(
        user_id="test_user",
        session_id="integration_test",
    )

    # Run agent
    result = await agent.run(
        prompt="Research latest AI trends",
    )

    assert result["success"] is True


@pytest.mark.asyncio
async def test_langfuse_tracing():
    """Test LangFuse tracing integration."""
    agent = ResearchAgent(
        user_id="test_user",
        session_id="langfuse_test",
    )

    result = await agent.run(
        prompt="Test LangFuse tracing",
    )

    # Verify result
    assert result["success"] is True

    # Note: Check LangFuse dashboard manually for traces


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
EOF

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest backend/tests/ -v --cov=backend/app --cov-report=html
```

### Day 13-14: Documentation & CI/CD

```bash
# GitHub Actions ì›Œí¬í”Œë¡œìš° ìƒì„±
mkdir -p .github/workflows
cat > .github/workflows/test.yml << 'EOF'
name: Test

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
        pip install pytest pytest-asyncio pytest-cov

    - name: Run tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        LANGFUSE_PUBLIC_KEY: ${{ secrets.LANGFUSE_PUBLIC_KEY }}
        LANGFUSE_SECRET_KEY: ${{ secrets.LANGFUSE_SECRET_KEY }}
      run: |
        cd backend
        pytest tests/ -v --cov=app --cov-report=xml

    - name: Upload coverage
      uses: codecov/codecov-action@v3
      with:
        files: ./backend/coverage.xml
EOF
```

---

## ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Week 1 ì™„ë£Œ ê¸°ì¤€

#### LangChain í†µí•©
- [ ] LangChain ì„¤ì¹˜ ì™„ë£Œ
- [ ] BaseAgent í´ë˜ìŠ¤ êµ¬í˜„ ì™„ë£Œ
- [ ] ResearchAgent êµ¬í˜„ ë° í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Agentê°€ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰ ê°€ëŠ¥
- [ ] Agent ì‹¤í–‰ ê²°ê³¼ ì •ìƒ ë°˜í™˜

#### LangFuse í†µí•©
- [ ] LangFuse ê³„ì • ìƒì„± ë˜ëŠ” Self-Hosted ì„¤ì •
- [ ] LangFuse Callback Handler í†µí•©
- [ ] ëŒ€ì‹œë³´ë“œì—ì„œ Trace í™•ì¸ ê°€ëŠ¥
- [ ] LLM í˜¸ì¶œ ë¹„ìš© ì¶”ì  ê°€ëŠ¥
- [ ] ì—ëŸ¬ ì¶”ì  ì •ìƒ ì‘ë™

### Week 2 ì™„ë£Œ ê¸°ì¤€

#### Prompt Management
- [ ] PromptRegistry êµ¬í˜„ ì™„ë£Œ
- [ ] í”„ë¡¬í”„íŠ¸ ë“±ë¡/ì¡°íšŒ ê¸°ëŠ¥ ì‘ë™
- [ ] ë²„ì „ ê´€ë¦¬ ê¸°ëŠ¥ ì‘ë™
- [ ] Agentì—ì„œ Registry ì‚¬ìš© ê°€ëŠ¥

#### Testing
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ (80%+ ì»¤ë²„ë¦¬ì§€)
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± ì™„ë£Œ
- [ ] pytest ì‹¤í–‰ ì„±ê³µ
- [ ] Coverage ë¦¬í¬íŠ¸ ìƒì„±

#### CI/CD
- [ ] GitHub Actions ì›Œí¬í”Œë¡œìš° ì„¤ì •
- [ ] ìë™ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì„±ê³µ
- [ ] Coverage ì—…ë¡œë“œ ì„±ê³µ

#### Documentation
- [ ] ì½”ë“œ ì£¼ì„ ì‘ì„± ì™„ë£Œ
- [ ] README ì—…ë°ì´íŠ¸ ì™„ë£Œ
- [ ] API ë¬¸ì„œ ìƒì„± ì™„ë£Œ

---

## ë‹¤ìŒ ë‹¨ê³„ (Phase 1)

Phase 0 ì™„ë£Œ í›„ Phase 1ìœ¼ë¡œ ì§„í–‰:

1. **Research Agent ì™„ì „ êµ¬í˜„**
   - Playwright í†µí•©
   - Content Extraction
   - Source Citation

2. **Google Docs Agent êµ¬í˜„**
   - Google Docs API í†µí•©
   - Document ìƒì„± ê¸°ëŠ¥
   - ìŠ¤íƒ€ì¼ ì ìš©

3. **Google Sheets Agent êµ¬í˜„**
   - Google Sheets API í†µí•©
   - ë°ì´í„° êµ¬ì¡°í™”
   - ì°¨íŠ¸ ìƒì„±

4. **Google Slides Agent êµ¬í˜„**
   - Google Slides API í†µí•©
   - ìŠ¬ë¼ì´ë“œ ë ˆì´ì•„ì›ƒ
   - ì½˜í…ì¸  ë°°ì¹˜

---

## ì°¸ê³  ìë£Œ

### LangChain
- [Quick Start Guide](https://python.langchain.com/docs/get_started/quickstart)
- [Agent Documentation](https://python.langchain.com/docs/modules/agents/)
- [Custom Tools](https://python.langchain.com/docs/modules/agents/tools/custom_tools)

### LangFuse
- [Getting Started](https://langfuse.com/docs/get-started)
- [Python SDK](https://langfuse.com/docs/sdk/python)
- [LangChain Integration](https://langfuse.com/docs/integrations/langchain/tracing)

### Testing
- [pytest Documentation](https://docs.pytest.org/)
- [pytest-asyncio](https://pytest-asyncio.readthedocs.io/)
- [Coverage.py](https://coverage.readthedocs.io/)

---

**Last Updated**: 2024-10-29
**Phase**: 0
**Status**: Ready to Start
